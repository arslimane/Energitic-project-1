{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd52ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, LSTM,BatchNormalization,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64d883",
   "metadata": {},
   "source": [
    "# Lstm model after using encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321418fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_step=25 #to be changed after to 10,10\n",
    "output_step=50\n",
    "fsize=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93d8538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.load(\"X11_\"+str(input_step)+\".npy\")\n",
    "X2=np.load(\"X22_\"+str(input_step)+\".npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0dfa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=np.load(\"Y1_\"+str(output_step)+\".npy\",allow_pickle=True)\n",
    "Y2=np.load(\"Y2_\"+str(output_step)+\".npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a52d0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.float32(X1)\n",
    "X2=np.float32(X2)\n",
    "Y1=np.float32(Y1)\n",
    "Y2=np.float32(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d9670ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.reshape(X1,(X1.shape[0],input_step,fsize))\n",
    "X2=np.reshape(X2,(X2.shape[0],input_step,fsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47f83364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52316, 25, 64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a05633f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "XT=np.concatenate((X1, X2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c1e728c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "YT=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6d27a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(inputShape,output):\n",
    "# define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation='relu',input_shape=inputShape,return_sequences=True))\n",
    "    model.add(LSTM(100,activation='relu', return_sequences=False))\n",
    "#     model.add(LSTM(64,activation='relu', return_sequences=False))\n",
    "#     model.add(Dense(16, activation='linear'))\n",
    "#     model.add(Dropout(0.3))\n",
    "    model.add(Dense(output,activation=\"sigmoid\"))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt,loss='mae',metrics=['mae','mse',tf.keras.metrics.RootMeanSquaredError(),tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "    # model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b2789834",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = input_step  # Number of time steps\n",
    "feature_length = 64  # Length of each feature vector\n",
    "input_shape = (time_steps, feature_length)\n",
    "\n",
    "model=createModel(input_shape,output_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2d55aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_55 (LSTM)              (None, 25, 100)           66000     \n",
      "                                                                 \n",
      " lstm_56 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,450\n",
      "Trainable params: 151,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a4aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60a92db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606/2606 [==============================] - 182s 69ms/step - loss: 0.0670 - mae: 0.0670 - mse: 0.0438 - root_mean_squared_error: 0.2093 - mean_absolute_percentage_error: 7.0062\n",
      "652/652 [==============================] - 9s 14ms/step\n",
      "2606/2606 [==============================] - 183s 70ms/step - loss: 0.0074 - mae: 0.0074 - mse: 1.3348e-04 - root_mean_squared_error: 0.0116 - mean_absolute_percentage_error: 0.7837\n",
      "652/652 [==============================] - 10s 15ms/step\n",
      "2606/2606 [==============================] - 177s 68ms/step - loss: 0.0062 - mae: 0.0062 - mse: 1.0015e-04 - root_mean_squared_error: 0.0100 - mean_absolute_percentage_error: 0.6626\n",
      "652/652 [==============================] - 9s 14ms/step\n",
      "2606/2606 [==============================] - 191s 73ms/step - loss: 0.0057 - mae: 0.0057 - mse: 8.1232e-05 - root_mean_squared_error: 0.0090 - mean_absolute_percentage_error: 0.6021\n",
      "652/652 [==============================] - 10s 15ms/step\n",
      "2606/2606 [==============================] - 222s 85ms/step - loss: 0.0053 - mae: 0.0053 - mse: 7.0443e-05 - root_mean_squared_error: 0.0084 - mean_absolute_percentage_error: 0.5613\n",
      "652/652 [==============================] - 12s 18ms/step\n",
      "Validation mae: 0.00609 ± 0.00123\n",
      "Validation mse: 0.00010 ± 0.00004\n",
      "Validation mape: 0.64772 ± 0.13070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "# load your data\n",
    "X = XT  # your features\n",
    "y = YT  # your target variable\n",
    "\n",
    "# set up the k-fold cross-validation object\n",
    "k =5   # number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# initialize a list to store the validation accuracies\n",
    "val_mae = []\n",
    "val_mse = []\n",
    "val_mape=[]\n",
    "\n",
    "# loop over the k folds\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # split the data into training and validation sets\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "\n",
    "    # train your model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model on the validation set and store the mse\n",
    "    y_pred = model.predict(X_val)\n",
    "    val_acc = mean_absolute_error(y_val, y_pred)\n",
    "    val_mae.append(val_acc)\n",
    "    val_acc = mean_squared_error(y_val, y_pred)\n",
    "    val_mse.append(val_acc)\n",
    "    val_acc = MAPE(y_val, y_pred)\n",
    "    val_mape.append(val_acc)\n",
    "    \n",
    "\n",
    "# print the mean and standard deviation of the validation mse\n",
    "print(f'Validation mae: {np.mean(val_mae):.5f} ± {np.std(val_mae):.5f}')\n",
    "print(f'Validation mse: {np.mean(val_mse):.5f} ± {np.std(val_mse):.5f}')\n",
    "print(f'Validation mape: {np.mean(val_mape):.5f} ± {np.std(val_mape):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9afe6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623/1623 [==============================] - 28s 17ms/step - loss: 0.0044 - mae: 0.0044 - mse: 5.9308e-05 - root_mean_squared_error: 0.0077 - mean_absolute_percentage_error: 0.4721\n",
      "Test loss: 0.00443765614181757\n",
      "Test MAE: 0.00443765614181757\n",
      "Test MSE: 5.930836050538346e-05\n",
      "Test RMSE: 0.007701194379478693\n",
      "Test MAPE: 0.472080260515213\n"
     ]
    }
   ],
   "source": [
    "loss, mae,mse,rmse,mape = model.evaluate(X2, Y2)\n",
    "print('Test loss:', loss)\n",
    "print('Test MAE:', mae)\n",
    "print('Test MSE:', mse)\n",
    "print('Test RMSE:', rmse)\n",
    "print('Test MAPE:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daa927f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_model_withencoder_\"+str(input_step)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e353e",
   "metadata": {},
   "source": [
    "# CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc5c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 23, 4, 32)         144032    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 2, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 704)               0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 22, 32)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 22, 32)            8320      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                1650      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,322\n",
      "Trainable params: 162,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Define CNN-LSTM model architecture\n",
    "model2 = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(input_step, 6, 500)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten and reshape for LSTM\n",
    "model2.add(Flatten())\n",
    "model2.add(Reshape((22, 32)))\n",
    "\n",
    "# LSTM layers\n",
    "model2.add(LSTM(32, return_sequences=True))\n",
    "model2.add(LSTM(32, return_sequences=False))\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "model2.add(Dense(output_step, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model2.compile(loss='mean_absolute_error', optimizer=opt, metrics=['mae', 'mse', tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint = ModelCheckpoint(\"Cnn_lstm_model_\"+str(input_step)+\".h5\", save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Print model summary\n",
    "model2.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22d6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X11=np.load(\"X1_\"+str(input_step)+\".npy\")\n",
    "X22=np.load(\"X2_\"+str(input_step)+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb469055",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=np.load(\"Y1_\"+str(output_step)+\".npy\",allow_pickle=True)\n",
    "Y2=np.load(\"Y2_\"+str(output_step)+\".npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a932401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52316, 25, 6, 500), (51922, 25, 6, 500))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X11.shape,X22.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6e35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X11=np.float32(X11)\n",
    "X22=np.float32(X22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4df63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=np.float32(Y1)\n",
    "Y2=np.float32(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da303911",
   "metadata": {},
   "outputs": [],
   "source": [
    "XT=np.concatenate((X11, X22), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec239c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "YT=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a23a4068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606/2606 [==============================] - 87s 33ms/step - loss: 0.0317 - mae: 0.0317 - mse: 0.0039 - root_mean_squared_error: 0.0622 - mean_absolute_percentage_error: 3.3836\n",
      "652/652 [==============================] - 14s 21ms/step\n",
      "2606/2606 [==============================] - 85s 32ms/step - loss: 0.0096 - mae: 0.0096 - mse: 2.4403e-04 - root_mean_squared_error: 0.0156 - mean_absolute_percentage_error: 1.0229\n",
      "652/652 [==============================] - 12s 18ms/step\n",
      "2606/2606 [==============================] - 78s 30ms/step - loss: 0.0075 - mae: 0.0075 - mse: 1.4484e-04 - root_mean_squared_error: 0.0120 - mean_absolute_percentage_error: 0.8021\n",
      "652/652 [==============================] - 11s 17ms/step\n",
      "2606/2606 [==============================] - 91s 35ms/step - loss: 0.0068 - mae: 0.0068 - mse: 1.1436e-04 - root_mean_squared_error: 0.0107 - mean_absolute_percentage_error: 0.7247\n",
      "652/652 [==============================] - 12s 18ms/step\n",
      "2606/2606 [==============================] - 91s 35ms/step - loss: 0.0063 - mae: 0.0063 - mse: 9.7707e-05 - root_mean_squared_error: 0.0099 - mean_absolute_percentage_error: 0.6644\n",
      "652/652 [==============================] - 10s 15ms/step\n",
      "Validation mae: 0.00798 ± 0.00253\n",
      "Validation mse: 0.00017 ± 0.00012\n",
      "Validation mape: 0.84733 ± 0.26945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import gc\n",
    "X = XT  # your features\n",
    "y = YT  # your target variable\n",
    "\n",
    "# set up the k-fold cross-validation object\n",
    "k =5   # number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# initialize a list to store the validation accuracies\n",
    "val_mae = []\n",
    "val_mse = []\n",
    "val_mape=[]\n",
    "\n",
    "# loop over the k folds\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # split the data into training and validation sets\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "\n",
    "    # train your model on the training set\n",
    "    model2.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model on the validation set and store the mse\n",
    "    y_pred = model2.predict(X_val)\n",
    "    val_acc = mean_absolute_error(y_val, y_pred)\n",
    "    val_mae.append(val_acc)\n",
    "    val_acc = mean_squared_error(y_val, y_pred)\n",
    "    val_mse.append(val_acc)\n",
    "    val_acc = MAPE(y_val, y_pred)\n",
    "    val_mape.append(val_acc)\n",
    "    del X_train,y_train,X_val,y_val\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "# print the mean and standard deviation of the validation mse\n",
    "print(f'Validation mae: {np.mean(val_mae):.5f} ± {np.std(val_mae):.5f}')\n",
    "print(f'Validation mse: {np.mean(val_mse):.5f} ± {np.std(val_mse):.5f}')\n",
    "print(f'Validation mape: {np.mean(val_mape):.5f} ± {np.std(val_mape):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03c7930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0039 - mae: 0.0039 - mse: 3.7264e-05 - root_mean_squared_error: 0.0061 - mean_absolute_percentage_error: 0.4098\n",
      "Test loss: 0.0038862728979438543\n",
      "Test MAE: 0.0038862728979438543\n",
      "Test MSE: 3.7264293496264145e-05\n",
      "Test RMSE: 0.0061044516041874886\n",
      "Test MAPE: 0.4098218083381653\n"
     ]
    }
   ],
   "source": [
    "loss, mae,mse,rmse,mape = model2.evaluate(X22, Y2)\n",
    "print('Test loss:', loss)\n",
    "print('Test MAE:', mae)\n",
    "print('Test MSE:', mse)\n",
    "print('Test RMSE:', rmse)\n",
    "print('Test MAPE:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f556815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"Cnn_lstm_model_\"+str(input_step)+\".h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
